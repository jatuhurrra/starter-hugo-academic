---
# An instance of the Experience widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: projects

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 40

title: Projects
subtitle: 'Project Desc. & Datasets'

design:
  columns: '2'

# This is the first attempt at writing a project slide.

---

<style> 

.project-title {
   margin-bottom: 10px;
   margin-top: 40px;  /* Space above each section */
   font-size: 24px;
   font-weight: bold;
   color: violet;   /* violet appeared beautiful on the page */
   margin-bottom: 5px;  
   font-weight: bold;
}

.project-details {
   margin-bottom: 10px;
   margin-top: 10px;  /* Space above each section */
   font-size: 18px;
}
</style>


<h4 class="project-title">LLMs for Bio-species Infomation Extraction</h4>

<div class='project-details'>
Latent composability of the best models is only about 5% for the test queries where the bridge entity is a year, but the number is above 80% when the bridge entity is a country. Latent composability tends to increase roughly linearly with respect to the number of known single-hop facts, and tends to be higher for larger models, but the rate of increment and the gain from model scale also significantly differs according to the type of the bridge entity. Comparisons with Chain-of-Thought composability highlight a significant gap between latent and explicit reasoning. By performing initial investigations and drawing connections to related works, we suggest several unlikely and plausible hypotheses on the factors that may determine latent compositionality. In sum, our work provides the resource, insights, and potential future directions for precise evaluation, understanding, and improvement of latent reasoning of LLMs.
</div>

<h4 class="project-title">Large-scale NER Dataset Corpus</h4>

<div class='project-details'>
Latent composability of the best models is only about 5% for the test queries where the bridge entity is a year, but the number is above 80% when the bridge entity is a country. Latent composability tends to increase roughly linearly with respect to the number of known single-hop facts, and tends to be higher for larger models, but the rate of increment and the gain from model scale also significantly differs according to the type of the bridge entity. Comparisons with Chain-of-Thought composability highlight a significant gap between latent and explicit reasoning. By performing initial investigations and drawing connections to related works, we suggest several unlikely and plausible hypotheses on the factors that may determine latent compositionality. In sum, our work provides the resource, insights, and potential future directions for precise evaluation, understanding, and improvement of latent reasoning of LLMs.
</div>
